{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62a85271",
   "metadata": {},
   "source": [
    "# Speed Train CNN Cifar-10\n",
    "\n",
    "This notebook will train a CNN on cifar-10 dataset using pytorch and optimized hyperparameters to achieve a high accuracy and a very low training time.\n",
    "\n",
    "## Hyperparameter choices for the CNN on CIFAR-10 dataset\n",
    "- **Batch size**: 128\n",
    "- **Learning rate**: 0.001\n",
    "- **Epochs**: 10\n",
    "- **Optimizer**: Adam\n",
    "- **Loss function**: CrossEntropyLoss\n",
    "- **Data augmentation**: RandomHorizontalFlip, RandomCrop\n",
    "- **Normalization**: Normalize with mean and std of CIFAR-10 dataset\n",
    "- **Model architecture**: 3 convolutional layers with ReLU activation, followed by max pooling and dropout, and a fully connected layer at the end.\n",
    "- **Regularization**: Dropout with a probability of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Load Cifar-10 dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# Set the random seed\n",
    "set_seed(42)\n",
    "\n",
    "# Define the device to be used for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the data transformations\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ab5b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "\n",
    "# Define the ResNet model\n",
    "# Define the basic residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += self.shortcut(residual)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# Define the ResNet model for CIFAR-10\n",
    "class ResNetCIFAR10(L.LightningModule):\n",
    "    def __init__(self, num_classes=10, lr: float = 0.001):\n",
    "        self.lr = lr\n",
    "        super(ResNetCIFAR10, self).__init__()\n",
    "\n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # 3 residual blocks (with conv layers)\n",
    "        self.layer1 = ResidualBlock(64, 64)\n",
    "        self.layer2 = ResidualBlock(64, 128, stride=2)\n",
    "        self.layer3 = ResidualBlock(128, 256, stride=2)\n",
    "\n",
    "        # Max pooling\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(256 * 4 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "\n",
    "        out = self.maxpool(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)  # Flatten\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        # log accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        # log accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        self.log(\"val_acc\", acc)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86199e6",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed77c5bc",
   "metadata": {},
   "source": [
    "## Search for optimal Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a181a0c",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b80d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = L.pytorch.loggers.WandbLogger(\n",
    "    project=\"cifar10\",\n",
    "    log_model=\"all\",\n",
    "    save_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=15,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[L.pytorch.callbacks.EarlyStopping(monitor=\"train_loss\", patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbde21",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b559e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = ResNetCIFAR10().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10730439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|                                                           | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|████████████████████████| 782/782 [05:31<00:00,  2.36it/s, loss=0.7974, acc=48.46%]\n",
      "Testing: 100%|███████████████████████████| 157/157 [00:37<00:00,  4.22it/s, loss=1.1746, acc=62.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Test Accuracy: 62.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████| 782/782 [06:17<00:00,  2.07it/s, loss=0.6046, acc=66.41%]\n",
      "Testing: 100%|███████████████████████████| 157/157 [00:35<00:00,  4.39it/s, loss=0.6129, acc=71.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Test Accuracy: 71.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  12%|██▉                      | 90/782 [00:55<05:18,  2.17it/s, loss=0.6200, acc=72.29%]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
